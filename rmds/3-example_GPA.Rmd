---
title: "Model Selection"
subtitle: "GPA Example" 
output:
  html_document:
    toc: yes
---

<style type="text/css">
  body{
  font-size: 14pt;
}
</style>

```{r setup2, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
packages_needed <- c("ggplot2",
                     "patchwork",
                     "MuMIn",
                     "olsrr"
                     )
pk_to_install <- packages_needed [!( packages_needed %in% rownames(installed.packages())  )]
if(length(pk_to_install)>0 ){
  install.packages(pk_to_install,repos="http://cran.r-project.org")
}
#lapply(packages_needed, require, character.only = TRUE)
library(ggplot2)
library(patchwork)
library(MuMIn)
library(olsrr) #added variable plot
```

```{r, include=FALSE}
# change na. action
options(na.action = "na.fail")
```
GPA example from Graybill and Iyer (1994); worked in Burnham and Anderson (2002; p. 226)

SAT scores for Math and Verbal sections; High School GPAs for Math and English; GPA is the first-year 
college Grade Point Average (GPA).

```{r}
GPA_data <- read.csv("../data/GPA.txt", sep="")
```

```{r preview data}
head(GPA_data)
```


```{r fig.height=8, fig.width=8}
#check for co-linearity
pairs(GPA_data[,3:6], lower.panel = NULL)
```
```{r look at the correlation matrix}
correlation.matrix <- cor(GPA_data[,3:6])
round(correlation.matrix, 2)
```

Some apparent colinearity among variables (HSverbal and SATmath). Anything above ~0.5 we should look at, but OK for now.

```{r}
# fit the full model with all parameters (sometimes called 'global')
GPA.all.parms <-lm (GPA ~ SATmath + SATverbal + HSmath + HSverbal, data = GPA_data)
```

**Added variable plots** are a quick diagnosis to see what variables in the global
model are likely to be influential.

```{r message=FALSE, warning=FALSE}
olsrr::ols_plot_added_variable(GPA.all.parms)
#added variable plot is also called a partial regression plot; effect of one variable while holding others constant
```

https://olsrr.rsquaredacademy.com/articles/regression_diagnostics

Added variable plot provides information about the marginal (adjusted) importance of a predictor variable ð‘‹, given the other predictor variables already in the model. It shows the marginal importance of the variable in reducing the residual (unexplained) variability.

The added variable plot was introduced by Mosteller and Tukey (1977). It enables us to visualize the regression coefficient of a new variable being considered to be included in a model. The plot can be constructed for each predictor variable.

A strong pos/neg relationship in the added variable plot indicates the increased importance of the contribution of X to the model **already containing the other predictors**.

In this case *HSverbal* doesn't look like it contributes much explanatory power to the full model (very flat slope).

```{r message=FALSE, warning=FALSE}
# the dredge function fits all combinations
# of the variables in the GPA.all.parms model fit above
results <- MuMIn::dredge(GPA.all.parms) # note use of 'MuMIn' package
results
```

```{r}
# grab best supported models
subset(results, delta <5)
```
Models 14 and 13 have delta AICc <2. Model 14 is about 1.69 times more likely than Model 13 (0.485/0.287=1.69).
```{r}
# calculate variable importance weights
MuMIn::sw(results)
```
Tells us that HSverbal is not really a useful predictor, and it is absent in all of the 3 top models.

Only fit models without HSverbal.

```{r message=FALSE, warning=FALSE}
results<-dredge(GPA.all.parms, subset= !(HSverbal))
results
```
Again, the model selection results without including HSverbal are the same as those including HSverbal; Models 13 and 14 have about equal explanatory power (delta AICc <2). The inclusion of HSmath does not explain additional variation above what is explained by the other three variables; inclusion of HSmath means a 1 parameter "penalty". Model 14 is about 1.69 times more likely than Model 13 (0.532/0.315=1.69). This re-scaled result is the same as before. 

```{r make a figure using best-fit model, message=FALSE, warning=FALSE, fig.width=9.5}
#trying to represent combinations of our three most important variables on predicting GPA
p3 <- ggplot(GPA_data, aes(SATmath, GPA, colour = SATverbal)) + 
  geom_point(size=3) +
  geom_smooth(method="lm") +
  scale_colour_gradientn(colours = terrain.colors(10, rev=TRUE))

p4 <- ggplot(GPA_data, aes(SATverbal, GPA, colour = HSmath)) + 
  geom_point(size=3) +
  geom_smooth(method="lm") +
  scale_colour_gradientn(colours = heat.colors(10, rev=TRUE))
                     
p3+p4 #uses 'patchwork' library to put plots next to each other

#these figure plot raw data. You could also make partial variable plots (aka added variable plots) to show statistical fits of regression lines for variables retained in the top model.
```

"Dredging" used here is just an example for comparing models. Dregding is known to prefer over-complex models.
https://dynamicecology.wordpress.com/2015/05/21/why-aic-appeals-to-ecologists-lowest-instincts/
